
# Spark GradientBoostedTrees(ä¸‰)å›å½’æ ‘å»ºç«‹
ä¸Šä¸€èŠ‚æˆ‘ä»¬åˆ†æäº† `GBDT` çš„è°ƒåº¦æµç¨‹ï¼Œå…¶ä¸­æœ€å…³é”®çš„æ˜¯å¦‚ä½•å»ºç«‹ä¸€é¢—å›å½’æ ‘ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°†åˆ†æå›å½’æ ‘çš„æ„å»ºè¿‡ç¨‹ï¼š
1. æ„é€ å…ƒæ•°æ®

	```
	val metadata =
		  DecisionTreeMetadata.buildMetadata(retaggedInput, strategy, numTrees, featureSubsetStrategy)
	```
	
	`buildMetadata` æ–¹æ³•å†…éƒ¨å®ç°é€»è¾‘ï¼š
	 * é¦–å…ˆè®¡ç®—ç‰¹å¾æ€»æ•°`numFeatures` å’Œ `maxPossibleBins(æ‰€æœ‰ç‰¹å¾çš„æœ€å¤§åˆ†å‰²æ•°)`ï¼Œ`maxPossibleBins`ç”±æˆ‘ä»¬æŒ‡å®šçš„ `maxBins` å’Œ `æ ·æœ¬æ€»é‡` å†³å®š
	`val maxPossibleBins = math.min(strategy.maxBins, numExamples).toInt`
	 * ç„¶åä¼šåˆ¤æ–­åˆ†ç±»å˜é‡çš„`ç‰¹å¾å€¼æ•°`ï¼Œåˆ†ç±»å˜é‡çš„ç‰¹å¾å€¼æ•°å¿…é¡»å°äº `maxPossibleBins`
	 * æœ€åè®¡ç®—æ¯ä¸ªç‰¹å¾çš„åˆ†å‰²æ•°`numBins`ï¼Œå¯¹äºåˆ†ç±»å˜é‡ï¼Œåˆ†å‰²æ•°ç­‰äºç‰¹å¾å€¼æ•°
	 * æ„å»º `DecisionTreeMetadata` å¯¹è±¡
	```
		new DecisionTreeMetadata(numFeatures, numExamples, numClasses, numBins.max,
		  strategy.categoricalFeaturesInfo, unorderedFeatures.toSet, numBins,
		  strategy.impurity, strategy.quantileCalculationStrategy, strategy.maxDepth,
		  strategy.minInstancesPerNode, strategy.minInfoGain, numTrees, numFeaturesPerNode)
	```
* `numClasses`ï¼šç±»åˆ«æ•°ï¼Œæ„å»ºå›å½’æ ‘æ—¶ä¸º`0`
* `numFeaturesPerNode`ï¼šæ¯ä¸ªæ ‘èŠ‚ç‚¹çš„ç‰¹å¾æ€»æ•°ï¼Œç”±`featureSubsetStrategy`å†³å®šï¼Œä¸»è¦ç”¨äº`RandomForest`ï¼Œ`GBDT`è¿”å›æ‰€æœ‰ç‰¹å¾

2. è®¡ç®—æ¯ä¸ªç‰¹å¾çš„æ‰€æœ‰å¯é€‰åˆ†å‰²é˜ˆå€¼

	```
	val splits = findSplits(retaggedInput, metadata, seed)
	```
	
`findSplits` åªè®¡ç®—è¿ç»­ç‰¹å¾çš„åˆ†å‰²ï¼Œå¯¹äºåˆ†ç±»ç‰¹å¾ï¼Œç›´æ¥è¿”å›ç©ºæ•°ç»„ï¼Œå†…éƒ¨é€»è¾‘å¦‚ä¸‹ï¼š
 * å…ˆå¯¹æ•°æ®é‡‡æ ·ï¼Œå› ä¸ºä½¿ç”¨é‡‡ç”¨æ•°æ®ï¼Œç®—æ³•èƒ½å¤Ÿå¾—åˆ°æ›´å¥½çš„æ•ˆæœ

	```
	val requiredSamples = math.max(metadata.maxBins * metadata.maxBins, 10000)

	```

 * å¯¹äºå¾—åˆ°çš„é‡‡æ ·æ•°æ®è°ƒç”¨ `findSplitsBySorting` æ–¹æ³•
 * 
	 ```
	 findSplitsBySorting(sampledInput, metadata, continuousFeatures)
	 ```
	 
`findSplitsBySorting` æ–¹æ³•å¯¹äºåˆ†ç±»ç‰¹å¾ç›´æ¥è¿”å›ç©ºæ•°ç»„ï¼Œå¯¹äºæ¯ä¸ªè¿ç»­ç‰¹å¾ï¼Œè°ƒç”¨ `findSplitsForContinuousFeature` æ–¹æ³•è·å¾—æ‰€æœ‰å¯èƒ½çš„åˆ†å‰²ï¼Œå°†è¿”å›çš„æ¯ä¸ªåˆ†å‰²ç‚¹åŒ…è£…æˆ`ContinuousSplit`å¯¹è±¡ï¼Œ`findSplitsForContinuousFeature`æ–¹æ³•å†…éƒ¨é€»è¾‘å¦‚ä¸‹ï¼š
 * é¦–å…ˆç»Ÿè®¡æ¯ä¸ªè¿ç»­ç‰¹å¾æ‰€æœ‰çš„å€¼åŠå‡ºç°çš„æ¬¡æ•°ï¼Œ`å”¯ä¸€ç‰¹å¾çš„æ€»æ•°-1`å³ä¸ºåˆ†å‰²ç‚¹æ•°
 * ç„¶åæŒ‰å€¼ä»å°æ‰“åˆ°å¤§æ’åºï¼Œå¦‚æœåˆ†å‰²ç‚¹ä¸º`0`ï¼Œè¿”å›ç©ºæ•°ç»„ï¼Œå¦‚æœåˆ†å‰²ç‚¹æ•°å°äºç­‰äº`numSplits`ï¼Œåˆ™æ¯ä¸ªåˆ†å‰²ç‚¹ä¸ºå‰åä¸¤ä¸ªç‰¹å¾å€¼çš„å‡å€¼ï¼Œå¦åˆ™ï¼ŒæŒ‰æ­¥é•¿åšåˆ†å‰²(è¿™é‡ŒåŸç†æ²¡çœ‹æ‡‚ğŸ˜”)

	```
	  def numSplits(featureIndex: Int): Int = if (isUnordered(featureIndex)) {
		numBins(featureIndex)
	  } else {
		numBins(featureIndex) - 1
	  }
	```

3. å°†`LabeledPoint`å¯¹è±¡è½¬æ¢æˆ`TreePoint`ï¼Œæ–¹æ³•è®¡ç®—äº†`thresholds`ä¸`featureArity`ï¼Œæœ€åè°ƒç”¨æ–¹æ³•`TreePoint.labeledPointToTreePoint`ï¼Œå¯¹è¿ç»­ç‰¹å¾ä½¿ç”¨äºŒåˆ†æœç´¢è®¡ç®—æ¯ä¸ªæ ·æœ¬æ•°æ®ç‚¹ä¸­çš„æ¯ä¸ªç‰¹å¾å€¼ï¼Œåœ¨è¯¥ç‰¹å¾æ‰€æœ‰åˆ†å‰²ç‚¹çš„æœ€ä½³åˆ†å‰²é˜ˆå€¼åŠç´¢å¼•ï¼Œåˆ†ç±»ç‰¹å¾ç›´æ¥è¿”å›ç‰¹å¾å€¼ï¼Œä»¥å¤‡è®¡ç®—æœ€ä½³åˆ†å‰²ç‚¹

	```
	  val treeInput = TreePoint.convertToTreeRDD(retaggedInput, splits, metadata)
	  def convertToTreeRDD(
		  input: RDD[LabeledPoint],
		  splits: Array[Array[Split]],
		  metadata: DecisionTreeMetadata): RDD[TreePoint] = {
		// Construct arrays for featureArity for efficiency in the inner loop.
		val featureArity: Array[Int] = new Array[Int](metadata.numFeatures)
		var featureIndex = 0
		while (featureIndex < metadata.numFeatures) {
		  featureArity(featureIndex) = metadata.featureArity.getOrElse(featureIndex, 0)
		  featureIndex += 1
		}
		val thresholds: Array[Array[Double]] = featureArity.zipWithIndex.map { case (arity, idx) =>
		  if (arity == 0) {
			splits(idx).map(_.asInstanceOf[ContinuousSplit].threshold)
		  } else {
			Array.empty[Double]
		  }
		}
		input.map { x =>
		  TreePoint.labeledPointToTreePoint(x, thresholds, featureArity)
		}
	  }
	```
	
4. å°†`TreePoint`è½¬æ¢æˆ`BaggedPoint`å¯¹è±¡ï¼Œå†…éƒ¨ä¸ºæ¯ä¸ªæ ·æœ¬èµ‹æƒé‡ï¼Œå¯¹äº`GBDT`ç®—æ³•ï¼Œæ‰€æœ‰æ ·æœ¬çš„æƒé‡è®¾ç½®ä¸º`1.0`

	```
		val baggedInput = BaggedPoint
		  .convertToBaggedRDD(treeInput, strategy.subsamplingRate, numTrees, withReplacement, seed)
		  .persist(StorageLevel.MEMORY_AND_DISK)
	```
	
5. æ„é€ æ¯é¢—æ ‘çš„æ ¹èŠ‚ç‚¹ï¼Œå¯¹äº`GBDT`ï¼Œåªèƒ½åœ¨å•é¢—æ ‘ä¸Šå¹¶è¡Œï¼Œæ‰€æœ‰æ¯æ¬¡åªæ„å»ºä¸€é¢—å›å½’æ ‘ï¼Œ`RandomForest`åˆ™å¹¶è¡Œæ„å»ºå¤šé¢—å†³ç­–æ ‘

	```
		val nodeStack = new mutable.Stack[(Int, LearningNode)]

		val rng = new Random()
		rng.setSeed(seed)

		// Allocate and queue root nodes.
		val topNodes = Array.fill[LearningNode](numTrees)(LearningNode.emptyNode(nodeIndex = 1))
		Range(0, numTrees).foreach(treeIndex => nodeStack.push((treeIndex, topNodes(treeIndex))))
	```
	
6. è°ƒç”¨`selectNodesToSplit`æ–¹æ³•è¿”å›è¯¥æ¬¡éœ€è¦åˆ†è£‚çš„æ‰€æœ‰èŠ‚ç‚¹ï¼Œè°ƒç”¨`findBestSplits`æ‰¾åˆ°æœ€ä½³çš„åˆ†è£‚ç‚¹ï¼Œè¿™ä¸¤ä¸ªæ–¹æ³•æ˜¯æ ‘æ„é€ çš„æ ¸å¿ƒï¼Œå°†åœ¨ä¸‹ä¸€èŠ‚è¯¦ç»†ä»‹ç»

	```
	while (nodeStack.nonEmpty) {
		  // Collect some nodes to split, and choose features for each node (if subsampling).
		  // Each group of nodes may come from one or multiple trees, and at multiple levels.
		  val (nodesForGroup, treeToNodeToIndexInfo) =
			RandomForest.selectNodesToSplit(nodeStack, maxMemoryUsage, metadata, rng)
		  // Sanity check (should never occur):
		  assert(nodesForGroup.nonEmpty,
			s"RandomForest selected empty nodesForGroup.  Error for unknown reason.")

		  // Only send trees to worker if they contain nodes being split this iteration.
		  val topNodesForGroup: Map[Int, LearningNode] =
			nodesForGroup.keys.map(treeIdx => treeIdx -> topNodes(treeIdx)).toMap

		  // Choose node splits, and enqueue new nodes as needed.
		  timer.start("findBestSplits")
		  RandomForest.findBestSplits(baggedInput, metadata, topNodesForGroup, nodesForGroup,
			treeToNodeToIndexInfo, splits, nodeStack, timer, nodeIdCache)
		  timer.stop("findBestSplits")
		}
	```
7. å°†å†³ç­–æ ‘ä¿¡æ¯åŒ…è£…æˆ`DecisionTreeClassificationModel`å¯¹è±¡ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯åœ¨æ„å»ºå¯¹è±¡çš„è¿‡ç¨‹ä¸­ï¼Œä¼šè°ƒç”¨`rootNode.toNode`æ–¹æ³•å°†`LearnNode`è½¬æ¢æˆ`Node`
* éå¶å­èŠ‚ç‚¹

	```
		  new InternalNode(stats.impurityCalculator.predict, stats.impurity, stats.gain,
			leftChild.get.toNode, rightChild.get.toNode, split.get, stats.impurityCalculator)
	 ```
	 
* å¶å­èŠ‚ç‚¹

	 ```
		   new LeafNode(stats.impurityCalculator.predict, stats.impurity,
			 stats.impurityCalculator)
	```

* æ„é€ `DecisionTreeClassificationModel`å¯¹è±¡

	```
		parentUID match {
		  case Some(uid) =>
			if (strategy.algo == OldAlgo.Classification) {
			  topNodes.map { rootNode =>
				new DecisionTreeClassificationModel(uid, rootNode.toNode, numFeatures,
				  strategy.getNumClasses)
			  }
			} else {
			  topNodes.map { rootNode =>
				new DecisionTreeRegressionModel(uid, rootNode.toNode, numFeatures)
			  }
			}
		  case None =>
			if (strategy.algo == OldAlgo.Classification) {
			  topNodes.map { rootNode =>
				new DecisionTreeClassificationModel(rootNode.toNode, numFeatures,
				  strategy.getNumClasses)
			  }
			} else {
			  topNodes.map(rootNode => new DecisionTreeRegressionModel(rootNode.toNode, numFeatures))
			}
		}
	```
